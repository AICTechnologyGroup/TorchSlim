<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>optimization.pruning.core.filter_prune API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>optimization.pruning.core.filter_prune</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import logging
import math
import numpy as np
import torch

from .weight_masker import WeightMasker


__all__ = [&#39;L1FilterPrunerMasker&#39;, &#39;L2FilterPrunerMasker&#39;, &#39;FPGMPrunerMasker&#39;, &#39;TaylorFOWeightFilterPrunerMasker&#39;, &#39;ActivationAPoZRankFilterPrunerMasker&#39;, &#39;ActivationMeanRankFilterPrunerMasker&#39;, &#39;SlimPrunerMasker&#39;]

_logger = logging.getLogger(__name__)


class StructuredWeightMasker(WeightMasker):

    def __init__(self, model, pruner, preserve_round = 1, dependency_aware = False, global_sort = False):
        &#34;&#34;&#34;
        A structured pruning masker base class that prunes convolutional layer filters.

        Parameters
        ----------
        model: nn.Module
            model to be pruned
        pruner: Pruner
            A Pruner instance used to prune the model
        preserve_round: int
            after pruning, preserve filters/channels round to `preserve_round`, for example:
            for a Conv2d layer, output channel is 32, sparsity is 0.2, if preserve_round is
            1 (no preserve round), then there will be int(32 * 0.2) = 6 filters pruned, and
            32 - 6 = 26 filters are preserved. If preserve_round is 4, preserved filters will
            be round up to 28 (which can be divided by 4) and only 4 filters are pruned.

        &#34;&#34;&#34;
        self.model = model
        self.pruner = pruner
        self.preserve_round = preserve_round
        self.dependency_aware = dependency_aware
        self.global_sort = global_sort


    def calc_mask(self, sparsity, wrapper, wrapper_idx=None, **depen_kwargs):
        &#34;&#34;&#34;
        calculate the mask for `wrapper`.

        Parameters
        ----------
        sparsity: float/list of float
            The target sparsity of the wrapper. If we calculate the mask in
            the normal way, then sparsity is a float number. In contrast, if
            we calculate the mask in the dependency-aware way, sparsity is a
            list of float numbers, each float number corressponds to a sparsity
            of a layer.
        wrapper: PrunerModuleWrapper/list of PrunerModuleWrappers
            The wrapper of the target layer. If we calculate the mask in the normal
            way, then `wrapper` is an instance of PrunerModuleWrapper, else `wrapper`
            is a list of PrunerModuleWrapper.
        wrapper_idx: int/list of int
            The index of the wrapper.
        depen_kwargs: dict
            The kw_args for the dependency-aware mode.
        &#34;&#34;&#34;
        if self.global_sort:
            return self._global_calc_mask(sparsity, wrapper, wrapper_idx)
        
        elif not self.dependency_aware:
            return self._normal_calc_mask(sparsity, wrapper, wrapper_idx)
        
        else:
            return self._dependency_calc_mask(sparsity, wrapper, wrapper_idx)

    def _get_current_state(self, sparsity, wrapper, wrapper_idx=None):
        &#34;&#34;&#34;
        Some pruner may prune the layers in a iterative way. In each pruning iteration,
        we may get the current state of this wrapper/layer, and continue to prune this layer
        based on the current state. This function is to get the current pruning state of the
        target wrapper/layer.
        Parameters
        ----------
        sparsity: float
            pruning ratio,  preserved weight ratio is `1 - sparsity`
        wrapper: PrunerModuleWrapper
            layer wrapper of this layer
        wrapper_idx: int
            index of this wrapper in pruner&#39;s all wrappers
        Returns
        -------
        base_mask: dict
            dict object that stores the mask of this wrapper in this iteration, if it is the
            first iteration, then we create a new mask with all ones. If there is already a
            mask in this wrapper, then we return the existing mask.
        weight: tensor
            the current weight of this layer
        num_prune: int
            how many filters we should prune
        &#34;&#34;&#34;
        msg = &#39;module type {} is not supported!&#39;.format(wrapper.type)

        assert wrapper.type == &#34;Conv2d&#34;, msg
        weight = wrapper.module.weight.data

        bias = None
        if hasattr(wrapper.module, &#39;bias&#39;) and wrapper.module.bias is not None:
            bias = wrapper.module.bias.data

        if wrapper.weight_mask is None:
            mask_weight = torch.ones(weight.size()).type_as(weight).detach()
        else:
            mask_weight = wrapper.weight_mask.clone()
        if bias is not None:
            if wrapper.bias_mask is None:
                mask_bias = torch.ones(bias.size()).type_as(bias).detach()
            else:
                mask_bias = wrapper.bias_mask.clone()
        else:
            mask_bias = None
        mask = {&#39;weight_mask&#39;: mask_weight, &#39;bias_mask&#39;: mask_bias}

        num_total = weight.size(0)
        num_prune = int(num_total * sparsity)
        if self.preserve_round &gt; 1:
            num_preserve = num_total - num_prune
            num_preserve = int(
                math.ceil(num_preserve * 1. / self.preserve_round) * self.preserve_round)
            if num_preserve &gt; num_total:
                num_preserve = int(math.floor(
                    num_total * 1. / self.preserve_round) * self.preserve_round)
            num_prune = num_total - num_preserve
        return mask, weight * mask_weight, num_prune

    def _global_calc_mask(self, sparsity, wrapper, wrapper_idx = None):
        num_prune = self._get_global_num_prune(wrapper, wrapper_idx)
        mask, weight, _ = self._get_current_state(sparsity, wrapper, wrapper_idx)
        return self.get_mask(mask, weight, num_prune, wrapper, wrapper_idx)

    def _normal_calc_mask(self, sparsity, wrapper, wrapper_idx=None):
        &#34;&#34;&#34;
        Calculate the mask of given layer.
        Parameters
        ----------
        sparsity: float
            pruning ratio,  preserved weight ratio is `1 - sparsity`
        wrapper: PrunerModuleWrapper
            layer wrapper of this layer
        wrapper_idx: int
            index of this wrapper in pruner&#39;s all wrappers
        Returns
        -------
        dict
            dictionary for storing masks, keys of the dict:
            &#39;weight_mask&#39;:  weight mask tensor
            &#39;bias_mask&#39;: bias mask tensor (optional)
        &#34;&#34;&#34;
        mask, weight, num_prune = self._get_current_state(sparsity, wrapper, wrapper_idx)
        num_total = weight.size(0)
        if num_total &lt; 2 or num_prune &lt; 1:
            return mask
        return self.get_mask(mask, weight, num_prune, wrapper, wrapper_idx)

    def _common_channel_to_prune(self, sparsities, wrappers, wrappers_idx, channel_dsets, groups):
        &#34;&#34;&#34;
        Calculate the common channels should be pruned by all the layers in this group.
        This function is for filter pruning of Conv layers. if want to support the dependency-aware
        mode for others ops, you need to inherit this class and overwrite `_common_channel_to_prune`.

        Parameters
        ----------
        sparsities : list
            List of float that specify the sparsity for each conv layer.
        wrappers : list
            List of wrappers
        groups : list
            The number of the filter groups of each layer.
        wrappers_idx : list
            The indexes of the wrappers
        &#34;&#34;&#34;
        for _w in wrappers:
            msg = &#39;module type {} is not supported!&#39;.format(_w.type)
            assert _w.type == &#34;Conv2d&#34;, msg

        if len(channel_dsets) == len(wrappers):
            min_sparsity = min(sparsities)
        else:
            min_sparsity = 0
        
        sparsities = [min_sparsity] * len(sparsities)
        max_group = np.lcm.reduce(groups)
        channel_count = wrappers[0].module.weight.data.size(0)
        device = wrappers[0].module.weight.device
        channel_sum = torch.zeros(channel_count).to(device)
        for _w, _w_idx in zip(wrappers, wrappers_idx):
            c_sum = self.get_channel_sum(_w, _w_idx)
            if c_sum is None:
                return None
            channel_sum += c_sum

        target_pruned = int(channel_count * min_sparsity)
        pruned_per_group = int(target_pruned / max_group)
        group_step = int(channel_count / max_group)

        channel_masks = []
        for gid in range(max_group):
            _start = gid * group_step
            _end = (gid + 1) * group_step

            if pruned_per_group &gt; 0:
                threshold = torch.topk(channel_sum[_start: _end], pruned_per_group, largest = False)[0].max()
                group_mask = torch.gt(channel_sum[_start: _end], threshold)

            else:
                group_mask = torch.ones(group_step).to(device)
            channel_masks.append(group_mask)

        channel_masks = torch.cat(channel_masks, dim=0)
        pruned_channel_index = (
            channel_masks == False).nonzero().squeeze(1).tolist()
        _logger.info(&#39;Prune the %s channels for all dependent&#39;,
                    &#39;,&#39;.join([str(x) for x in pruned_channel_index]))
        return channel_masks

    def _dependency_calc_mask(self, sparsities, wrappers, wrappers_idx, channel_dsets, groups):
        &#34;&#34;&#34;
        Calculate the masks for the layers in the same dependency sets.
        Similar to the traditional original calc_mask, _dependency_calc_mask
        will prune the target layers based on the L1/L2 norm of the weights.
        However, StructuredWeightMasker prunes the filter completely based on the
        L1/L2 norm of each filter. In contrast, _dependency_calc_mask
        will try to satisfy the channel/group dependency(see nni.compression.torch.
        utils.shape_dependency for details). Specifically, _dependency_calc_mask
        will try to prune the same channels for the layers that have channel dependency.
        In addition, this mask calculator will also ensure that the number of filters
        pruned in each group is the same(meet the group dependency).

        Parameters
        ----------
        sparsities : list
            List of float that specify the sparsity for each conv layer.
        wrappers : list
            List of wrappers
        groups : list
            The number of the filter groups of each layer.
        wrappers_idx : list
            The indexes of the wrappers
        &#34;&#34;&#34;
        channel_masks = self._common_channel_to_prune(sparsities, wrappers, wrappers_idx, channel_dsets, groups)
        masks = {}
        for _pos, _w in enumerate(wrappers):
            _w_idx = wrappers_idx[_pos]
            sparsity = sparsities[_pos]
            name = _w.name
            base_mask, current_weight, num_prune = self._get_current_state(
                sparsity, _w, _w_idx)
            num_total = current_weight.size(0)
            if num_total &lt; 2 or num_prune &lt; 1:
                masks[name] = base_mask
                continue
            _tmp_mask = self.get_mask(
                base_mask, current_weight, num_prune, _w, _w_idx, channel_masks)

            if _tmp_mask is None:
                return None
            masks[name] = _tmp_mask
        return masks

    def get_mask(self, base_mask, weight, num_prune, wrapper, wrapper_idx, channel_masks = None):
        &#34;&#34;&#34;
        Calculate the mask of given layer.

        Parameters
        ----------
        base_mask: dict
            The basic mask with the same shape of weight, all item in the basic mask is 1.
        weight: tensor
            the module weight to be pruned
        num_prune: int
            Num of filters to prune
        wrapper: PrunerModuleWrapper
            layer wrapper of this layer
        wrapper_idx: int
            index of this wrapper in pruner&#39;s all wrappers
        channel_masks: Tensor
            If mask some channels for this layer in advance. In the dependency-aware
            mode, before calculating the masks for each layer, we will calculate a common
            mask for all the layers in the dependency set. For the pruners that doesnot
            support dependency-aware mode, they can just ignore this parameter.

        Returns
        -------
        dict
            dictionary for storing masks
        &#34;&#34;&#34;
        raise NotImplementedError(&#39;{} get_mask is not implemented&#39;.format(self.__class__.__name__))
    
    def get_channel_sum(self, wrapper, wrapper_idx):
        &#34;&#34;&#34;
        Calculate the importance weight for each channel. If want to support the
        dependency-aware mode for this one-shot pruner, this function must be
        implemented.
        Parameters
        ----------
        wrapper: PrunerModuleWrapper
            layer wrapper of this layer
        wrapper_idx: int
            index of this wrapper in pruner&#39;s all wrappers
        Returns
        -------
        tensor
            Tensor that indicates the importance of each channel
        &#34;&#34;&#34;
        raise NotImplementedError(&#39;{} get_channel_sum is not implemented&#39;.format(self.__class__.__name__))


class L1FilterPrunerMasker(StructuredWeightMasker):
    &#34;&#34;&#34;
    A structured pruning algorithm that prunes the filters of smallest magnitude
    weights sum in the convolution layers to achieve a preset level of network sparsity.
    Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet and Hans Peter Graf,
    &#34;PRUNING FILTERS FOR EFFICIENT CONVNETS&#34;, 2017 ICLR
    https://arxiv.org/abs/1608.08710
    &#34;&#34;&#34;

    def get_mask(self, base_mask, weight, num_prune, wrapper, wrapper_idx, channel_masks=None):
        w_abs_structured = self.get_channel_sum(wrapper, wrapper_idx)
        if channel_masks is not None:
            w_abs_structured = w_abs_structured * channel_masks
        threshold = torch.topk(w_abs_structured.view(-1),num_prune, largest=False)[0].max()
        mask_weight = torch.gt(w_abs_structured, threshold)[
            :, None, None, None].expand_as(weight).type_as(weight)
        mask_bias = torch.gt(w_abs_structured, threshold).type_as(
            weight).detach() if base_mask[&#39;bias_mask&#39;] is not None else None
        return {&#39;weight_mask&#39;: mask_weight.detach(), &#39;bias_mask&#39;: mask_bias}

    def get_channel_sum(self, wrapper, wrapper_idx):
        weight = wrapper.module.weight.data
        filters = weight.shape[0]
        w_abs = weight.abs()
        w_abs_structured = w_abs.view(filters, -1).sum(dim=1)
        return w_abs_structured

class L2FilterPrunerMasker(StructuredWeightMasker):
    &#34;&#34;&#34;
    A structured pruning algorithm that prunes the filters with the
    smallest L2 norm of the weights.
    &#34;&#34;&#34;

    def get_mask(self, base_mask, weight, num_prune, wrapper, wrapper_idx, channel_masks=None):
        w_l2_norm = self.get_channel_sum(wrapper, wrapper_idx)
        if channel_masks is not None:
            w_l2_norm = w_l2_norm * channel_masks
        threshold = torch.topk(w_l2_norm.view(-1), num_prune, largest=False)[0].max()
        mask_weight = torch.gt(w_l2_norm, threshold)[:, None, None, None].expand_as(weight).type_as(weight)
        mask_bias = torch.gt(w_l2_norm, threshold).type_as(weight).detach() if base_mask[&#39;bias_mask&#39;] is not None else None

        return {&#39;weight_mask&#39;: mask_weight.detach(), &#39;bias_mask&#39;: mask_bias}

    def get_channel_sum(self, wrapper, wrapper_idx):
        weight = wrapper.module.weight.data
        filters = weight.shape[0]
        w = weight.view(filters, -1)
        w_l2_norm = torch.sqrt((w ** 2).sum(dim=1))
        return w_l2_norm

class FPGMPrunerMasker(StructuredWeightMasker):
    &#34;&#34;&#34;
    A filter pruner via geometric median.
    &#34;Filter Pruning via Geometric Median for Deep Convolutional Neural Networks Acceleration&#34;,
    https://arxiv.org/pdf/1811.00250.pdf
    &#34;&#34;&#34;
    def get_mask(self, base_mask, weight, num_prune, wrapper, wrapper_idx, channel_masks=None):
        min_gm_idx = self._get_min_gm_kernel_idx(
            num_prune, wrapper, wrapper_idx, channel_masks)
        for idx in min_gm_idx:
            base_mask[&#39;weight_mask&#39;][idx] = 0.
            if base_mask[&#39;bias_mask&#39;] is not None:
                base_mask[&#39;bias_mask&#39;][idx] = 0.
        return base_mask

    def _get_min_gm_kernel_idx(self, num_prune, wrapper, wrapper_idx, channel_masks):
        channel_dist = self.get_channel_sum(wrapper, wrapper_idx)
        if channel_masks is not None:
            channel_dist = channel_dist * channel_masks
        dist_list = [(channel_dist[i], i) for i in range(channel_dist.size(0))]
        min_gm_kernels = sorted(dist_list, key=lambda x: x[0])[:num_prune]
        return [x[1] for x in min_gm_kernels]

    def _get_distance_sum(self, weight, out_idx):
        &#34;&#34;&#34;
        Calculate the total distance between a specified filter (by out_idex and in_idx) and
        all other filters.
        Parameters
        ----------
        weight: Tensor
            convolutional filter weight
        out_idx: int
            output channel index of specified filter, this method calculates the total distance
            between this specified filter and all other filters.
        Returns
        -------
        float32
            The total distance
        &#34;&#34;&#34;
        _logger.debug(&#39;weight size: %s&#39;, weight.size())
        assert len(weight.size()) in [3, 4], &#39;unsupported weight shape&#39;

        w = weight.view(weight.size(0), -1)
        anchor_w = w[out_idx].unsqueeze(0).expand(w.size(0), w.size(1))
        x = w - anchor_w
        x = (x * x).sum(-1)
        x = torch.sqrt(x)
        return x.sum()

    def get_channel_sum(self, wrapper, wrapper_idx):
        weight = wrapper.module.weight.data
        assert len(weight.size()) in [3, 4]
        dist_list = []
        for out_i in range(weight.size(0)):
            dist_sum = self._get_distance_sum(weight, out_i)
            dist_list.append(dist_sum)
        return torch.Tensor(dist_list).to(weight.device)

class TaylorFOWeightFilterPrunerMasker(StructuredWeightMasker):    
    &#34;&#34;&#34;
    A structured pruning algorithm that prunes the filters with the smallest
    importance approximations based on the first order taylor expansion on the weight.
    Molchanov, Pavlo and Mallya, Arun and Tyree, Stephen and Frosio, Iuri and Kautz, Jan,
    &#34;Importance Estimation for Neural Network Pruning&#34;, CVPR 2019.
    http://jankautz.com/publications/Importance4NNPruning_CVPR19.pdf
    &#34;&#34;&#34;
    def __init__(self, model, pruner, statistics_batch_num=1):
        super().__init__(model, pruner)
        self.statistics_batch_num = statistics_batch_num
        self.pruner.iterations = 0
        self.pruner.set_wrappers_attribute(&#34;contribution&#34;, None)
        self.pruner.patch_optimizer(self.calc_contributions)
        self.global_threshold = None

    def _get_global_threshold(self):
        channel_contribution_list = []
        for wrapper_idx, wrapper in enumerate(self.pruner.get_modules_wrapper()):
            channel_contribution = self.get_channel_sum(wrapper, wrapper_idx)
            wrapper_size = wrapper.module.weight.size().numel()
            channel_size = wrapper.module.weight.size(0)
            contribution_expand = channel_contribution.expand(int(wrapper_size / channel_size), channel_size).reshape(-1)
            channel_contribution_list.append(contribution_expand)
        all_channel_contributions = torch.cat(channel_contribution_list)
        k = int(all_channel_contributions.shape[0] * self.pruner.config_list[0][&#39;sparsity&#39;])
        self.global_threshold = torch.topk(
            all_channel_contributions.view(-1), k, largest=False)[0].max()
    
    def _get_global_num_prune(self, wrapper, wrapper_idx):
        if self.global_threshold is None:
            self._get_global_threshold()
        weight = wrapper.module.weight.data
        filters = weight.size(0)
        channel_contribution = self.get_channel_sum(wrapper, wrapper_idx)
        num_prune = channel_contribution[channel_contribution &lt; self.global_threshold].size()[0]
        if num_prune == filters:
            num_prune -= 1
        return num_prune

    def get_mask(self, base_mask, weight, num_prune, wrapper, wrapper_idx, channel_masks=None):
        channel_contribution = self.get_channel_sum(wrapper, wrapper_idx)
        if channel_contribution is None:
            return None
        if channel_masks is not None:
            channel_contribution = channel_contribution * channel_masks
        prune_indices = torch.argsort(channel_contribution)[:num_prune]
        for idx in prune_indices:
            base_mask[&#39;weight_mask&#39;][idx] = 0.
            if base_mask[&#39;bias_mask&#39;] is not None:
                base_mask[&#39;bias_mask&#39;][idx] = 0.
        return base_mask

    def calc_contributions(self):
        &#34;&#34;&#34;
        Calculate the estimated importance of filters as a sum of individual contribution
        based on the first order taylor expansion.
        &#34;&#34;&#34;
        if self.pruner.iterations &gt;= self.statistics_batch_num:
            return

        for wrapper in self.pruner.get_modules_wrapper():
            filters = wrapper.module.weight.size(0)
            contribution = (
                wrapper.module.weight * wrapper.module.weight.grad).data.pow(2).view(filters, -1).sum(dim=1)
            if wrapper.contribution is None:
                wrapper.contribution = contribution
            else:
                wrapper.contribution += contribution

        self.pruner.iterations += 1

    def get_channel_sum(self, wrapper, wrapper_idx):
        if self.pruner.iterations &lt; self.statistics_batch_num:
            return None
        if wrapper.contribution is None:
            return None
        return wrapper.contribution


class ActivationFilterPrunerMasker(StructuredWeightMasker):

    def __init__(self, model, pruner, statistics_batch_num=1, activation=&#39;relu&#39;):
        super().__init__(model, pruner)
        self.statistics_batch_num = statistics_batch_num
        self.pruner.hook_id = self._add_activation_collector(self.pruner)
        self.pruner.iterations = 0
        self.pruner.patch_optimizer(self._iteration_counter)

        assert activation in [&#39;relu&#39;, &#39;relu6&#39;]
        if activation == &#39;relu&#39;:
            self.pruner.activation = torch.nn.functional.relu
        elif activation == &#39;relu6&#39;:
            self.pruner.activation = torch.nn.functional.relu6
        else:
            self.pruner.activation = None

    def _iteration_counter(self):
        self.pruner.iterations += 1

    def _add_activation_collector(self, pruner):
        def collector(collected_activation):
            def hook(module_, input_, output):
                collected_activation.append(
                    pruner.activation(output.detach().cpu()))
            return hook
        pruner.collected_activation = {}
        pruner._fwd_hook_id += 1
        pruner._fwd_hook_handles[pruner._fwd_hook_id] = []

        for wrapper_idx, wrapper in enumerate(pruner.get_modules_wrapper()):
            pruner.collected_activation[wrapper_idx] = []
            handle = wrapper.register_forward_hook(
                collector(pruner.collected_activation[wrapper_idx]))

            pruner._fwd_hook_handles[pruner._fwd_hook_id].append(handle)
        return pruner._fwd_hook_id

class ActivationAPoZRankFilterPrunerMasker(ActivationFilterPrunerMasker):
    &#34;&#34;&#34;
    A structured pruning algorithm that prunes the filters with the
    smallest APoZ(average percentage of zeros) of output activations.
    Hengyuan Hu, Rui Peng, Yu-Wing Tai and Chi-Keung Tang,
    &#34;Network Trimming: A Data-Driven Neuron Pruning Approach towards Efficient Deep Architectures&#34;, ICLR 2016.
    https://arxiv.org/abs/1607.03250
    &#34;&#34;&#34;
    def get_mask(self, base_mask, weight, num_prune, wrapper, wrapper_idx, channel_masks=None):
        apoz = self.get_channel_sum(wrapper, wrapper_idx)
        if apoz is None:
            return None
        if channel_masks is not None:
            apoz = apoz * channel_masks

        prune_indices = torch.argsort(apoz)[:num_prune]
        for idx in prune_indices:
            base_mask[&#39;weight_mask&#39;][idx] = 0.
            if base_mask[&#39;bias_mask&#39;] is not None:
                base_mask[&#39;bias_mask&#39;][idx] = 0.

        if self.pruner.hook_id in self.pruner._fwd_hook_handles:
            self.pruner.remove_activation_collector(self.pruner.hook_id)

        return base_mask

    def _calc_apoz(self, activations):
        &#34;&#34;&#34;
        Calculate APoZ(average percentage of zeros) of activations.

        Parameters
        ----------
        activations : list
            Layer&#39;s output activations

        Returns
        -------
        torch.Tensor
            Filter&#39;s APoZ(average percentage of zeros) of the activations
        &#34;&#34;&#34;
        activations = torch.cat(activations, 0)
        _eq_zero = torch.eq(activations, torch.zeros_like(activations))
        _apoz = torch.sum(_eq_zero, dim=(0, 2, 3), dtype=torch.float64) / torch.numel(_eq_zero[:, 0, :, :])
        return torch.ones_like(_apoz) - _apoz

    def get_channel_sum(self, wrapper, wrapper_idx):
        assert wrapper_idx is not None
        activations = self.pruner.collected_activation[wrapper_idx]
        if len(activations) &lt; self.statistics_batch_num:
            return None
        return self._calc_apoz(activations).to(wrapper.module.weight.device)

class ActivationMeanRankFilterPrunerMasker(ActivationFilterPrunerMasker):
    &#34;&#34;&#34;
    A structured pruning algorithm that prunes the filters with the
    smallest mean value of output activations.
    Pavlo Molchanov, Stephen Tyree, Tero Karras, Timo Aila and Jan Kautz,
    &#34;Pruning Convolutional Neural Networks for Resource Efficient Inference&#34;, ICLR 2017.
    https://arxiv.org/abs/1611.06440
    &#34;&#34;&#34;
    def get_mask(self, base_mask, weight, num_prune, wrapper, wrapper_idx, channel_masks=None):

        mean_activation = self.get_channel_sum(wrapper, wrapper_idx)
        if mean_activation is None:
            return None
        if channel_masks is not None:
            mean_activation = mean_activation * channel_masks

        prune_indices = torch.argsort(mean_activation)[:num_prune]
        for idx in prune_indices:
            base_mask[&#39;weight_mask&#39;][idx] = 0.
            if base_mask[&#39;bias_mask&#39;] is not None:
                base_mask[&#39;bias_mask&#39;][idx] = 0.
        if self.pruner.hook_id in self.pruner._fwd_hook_handles:
            self.pruner.remove_activation_collector(self.pruner.hook_id)

        return base_mask

    def _cal_mean_activation(self, activations):
        &#34;&#34;&#34;
        Calculate mean value of activations.

        Parameters
        ----------
        activations : list
            Layer&#39;s output activations

        Returns
        -------
        torch.Tensor
            Filter&#39;s mean value of the output activations
        &#34;&#34;&#34;
        activations = torch.cat(activations, 0)
        mean_activation = torch.mean(activations, dim=(0, 2, 3))
        return mean_activation

    def get_channel_sum(self, wrapper, wrapper_idx):
        assert wrapper_idx is not None
        activations = self.pruner.collected_activation[wrapper_idx]
        if len(activations) &lt; self.statistics_batch_num:
            return None
        return self._cal_mean_activation(activations).to(wrapper.module.weight.device)


class SlimPrunerMasker(WeightMasker):
    &#34;&#34;&#34;
    A structured pruning algorithm that prunes channels by pruning the weights of BN layers.
    Zhuang Liu, Jianguo Li, Zhiqiang Shen, Gao Huang, Shoumeng Yan and Changshui Zhang
    &#34;Learning Efficient Convolutional Networks through Network Slimming&#34;, 2017 ICCV
    https://arxiv.org/pdf/1708.06519.pdf
    &#34;&#34;&#34;
    def __init__(self, model, pruner, **kwargs):
        super().__init__(model, pruner)
        self.global_threshold = None

    def _get_global_threshold(self):
        weight_list = []
        for (layer, _) in self.pruner.get_modules_to_compress():
            weight_list.append(layer.module.weight.data.abs().clone())
        all_bn_weights = torch.cat(weight_list)
        k = int(all_bn_weights.shape[0] * self.pruner.config_list[0][&#39;sparsity&#39;])
        self.global_threshold = torch.topk(all_bn_weights.view(-1), k, largest=False)[0].max()
        print(f&#39;set global threshold to {self.global_threshold}&#39;)

    def calc_mask(self, sparsity, wrapper, wrapper_idx=None):
        assert wrapper.type == &#39;BatchNorm2d&#39;, &#39;SlimPruner only supports 2d batch normalization layer pruning&#39;

        if self.global_threshold is None:
            self._get_global_threshold()

        weight = wrapper.module.weight.data.clone()
        if wrapper.weight_mask is not None:
            weight = weight * wrapper.weight_mask

        base_mask = torch.ones(weight.size()).type_as(weight).detach()
        mask = {&#39;weight_mask&#39;: base_mask.detach(), &#39;bias_mask&#39;: base_mask.clone().detach()}
        filters = weight.size(0)
        num_prune = int(filters * sparsity)
        if filters &gt;= 2 and num_prune &gt;= 1:
            w_abs = weight.abs()
            mask_weight = torch.gt(
                w_abs, self.global_threshold).type_as(weight)
            mask_bias = mask_weight.clone()
            mask = {&#39;weight_mask&#39;: mask_weight.detach(), &#39;bias_mask&#39;: mask_bias.detach()}
        return mask
    </code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="optimization.pruning.core.filter_prune.ActivationAPoZRankFilterPrunerMasker"><code class="flex name class">
<span>class <span class="ident">ActivationAPoZRankFilterPrunerMasker</span></span>
<span>(</span><span>model, pruner, statistics_batch_num=1, activation='relu')</span>
</code></dt>
<dd>
<div class="desc"><p>A structured pruning algorithm that prunes the filters with the
smallest APoZ(average percentage of zeros) of output activations.
Hengyuan Hu, Rui Peng, Yu-Wing Tai and Chi-Keung Tang,
"Network Trimming: A Data-Driven Neuron Pruning Approach towards Efficient Deep Architectures", ICLR 2016.
<a href="https://arxiv.org/abs/1607.03250">https://arxiv.org/abs/1607.03250</a></p>
<p>A structured pruning masker base class that prunes convolutional layer filters.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>nn.Module</code></dt>
<dd>model to be pruned</dd>
<dt><strong><code>pruner</code></strong> :&ensp;<code>Pruner</code></dt>
<dd>A Pruner instance used to prune the model</dd>
<dt><strong><code>preserve_round</code></strong> :&ensp;<code>int</code></dt>
<dd>after pruning, preserve filters/channels round to <code>preserve_round</code>, for example:
for a Conv2d layer, output channel is 32, sparsity is 0.2, if preserve_round is
1 (no preserve round), then there will be int(32 * 0.2) = 6 filters pruned, and
32 - 6 = 26 filters are preserved. If preserve_round is 4, preserved filters will
be round up to 28 (which can be divided by 4) and only 4 filters are pruned.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ActivationAPoZRankFilterPrunerMasker(ActivationFilterPrunerMasker):
    &#34;&#34;&#34;
    A structured pruning algorithm that prunes the filters with the
    smallest APoZ(average percentage of zeros) of output activations.
    Hengyuan Hu, Rui Peng, Yu-Wing Tai and Chi-Keung Tang,
    &#34;Network Trimming: A Data-Driven Neuron Pruning Approach towards Efficient Deep Architectures&#34;, ICLR 2016.
    https://arxiv.org/abs/1607.03250
    &#34;&#34;&#34;
    def get_mask(self, base_mask, weight, num_prune, wrapper, wrapper_idx, channel_masks=None):
        apoz = self.get_channel_sum(wrapper, wrapper_idx)
        if apoz is None:
            return None
        if channel_masks is not None:
            apoz = apoz * channel_masks

        prune_indices = torch.argsort(apoz)[:num_prune]
        for idx in prune_indices:
            base_mask[&#39;weight_mask&#39;][idx] = 0.
            if base_mask[&#39;bias_mask&#39;] is not None:
                base_mask[&#39;bias_mask&#39;][idx] = 0.

        if self.pruner.hook_id in self.pruner._fwd_hook_handles:
            self.pruner.remove_activation_collector(self.pruner.hook_id)

        return base_mask

    def _calc_apoz(self, activations):
        &#34;&#34;&#34;
        Calculate APoZ(average percentage of zeros) of activations.

        Parameters
        ----------
        activations : list
            Layer&#39;s output activations

        Returns
        -------
        torch.Tensor
            Filter&#39;s APoZ(average percentage of zeros) of the activations
        &#34;&#34;&#34;
        activations = torch.cat(activations, 0)
        _eq_zero = torch.eq(activations, torch.zeros_like(activations))
        _apoz = torch.sum(_eq_zero, dim=(0, 2, 3), dtype=torch.float64) / torch.numel(_eq_zero[:, 0, :, :])
        return torch.ones_like(_apoz) - _apoz

    def get_channel_sum(self, wrapper, wrapper_idx):
        assert wrapper_idx is not None
        activations = self.pruner.collected_activation[wrapper_idx]
        if len(activations) &lt; self.statistics_batch_num:
            return None
        return self._calc_apoz(activations).to(wrapper.module.weight.device)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>optimization.pruning.core.filter_prune.ActivationFilterPrunerMasker</li>
<li>optimization.pruning.core.filter_prune.StructuredWeightMasker</li>
<li><a title="optimization.pruning.core.weight_masker.WeightMasker" href="weight_masker.html#optimization.pruning.core.weight_masker.WeightMasker">WeightMasker</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="optimization.pruning.core.filter_prune.ActivationAPoZRankFilterPrunerMasker.get_channel_sum"><code class="name flex">
<span>def <span class="ident">get_channel_sum</span></span>(<span>self, wrapper, wrapper_idx)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the importance weight for each channel. If want to support the
dependency-aware mode for this one-shot pruner, this function must be
implemented.
Parameters</p>
<hr>
<dl>
<dt><strong><code>wrapper</code></strong> :&ensp;<code>PrunerModuleWrapper</code></dt>
<dd>layer wrapper of this layer</dd>
<dt><strong><code>wrapper_idx</code></strong> :&ensp;<code>int</code></dt>
<dd>index of this wrapper in pruner's all wrappers</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tensor</code></dt>
<dd>Tensor that indicates the importance of each channel</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_channel_sum(self, wrapper, wrapper_idx):
    assert wrapper_idx is not None
    activations = self.pruner.collected_activation[wrapper_idx]
    if len(activations) &lt; self.statistics_batch_num:
        return None
    return self._calc_apoz(activations).to(wrapper.module.weight.device)</code></pre>
</details>
</dd>
<dt id="optimization.pruning.core.filter_prune.ActivationAPoZRankFilterPrunerMasker.get_mask"><code class="name flex">
<span>def <span class="ident">get_mask</span></span>(<span>self, base_mask, weight, num_prune, wrapper, wrapper_idx, channel_masks=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the mask of given layer.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>base_mask</code></strong> :&ensp;<code>dict</code></dt>
<dd>The basic mask with the same shape of weight, all item in the basic mask is 1.</dd>
<dt><strong><code>weight</code></strong> :&ensp;<code>tensor</code></dt>
<dd>the module weight to be pruned</dd>
<dt><strong><code>num_prune</code></strong> :&ensp;<code>int</code></dt>
<dd>Num of filters to prune</dd>
<dt><strong><code>wrapper</code></strong> :&ensp;<code>PrunerModuleWrapper</code></dt>
<dd>layer wrapper of this layer</dd>
<dt><strong><code>wrapper_idx</code></strong> :&ensp;<code>int</code></dt>
<dd>index of this wrapper in pruner's all wrappers</dd>
<dt><strong><code>channel_masks</code></strong> :&ensp;<code>Tensor</code></dt>
<dd>If mask some channels for this layer in advance. In the dependency-aware
mode, before calculating the masks for each layer, we will calculate a common
mask for all the layers in the dependency set. For the pruners that doesnot
support dependency-aware mode, they can just ignore this parameter.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>dictionary for storing masks</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_mask(self, base_mask, weight, num_prune, wrapper, wrapper_idx, channel_masks=None):
    apoz = self.get_channel_sum(wrapper, wrapper_idx)
    if apoz is None:
        return None
    if channel_masks is not None:
        apoz = apoz * channel_masks

    prune_indices = torch.argsort(apoz)[:num_prune]
    for idx in prune_indices:
        base_mask[&#39;weight_mask&#39;][idx] = 0.
        if base_mask[&#39;bias_mask&#39;] is not None:
            base_mask[&#39;bias_mask&#39;][idx] = 0.

    if self.pruner.hook_id in self.pruner._fwd_hook_handles:
        self.pruner.remove_activation_collector(self.pruner.hook_id)

    return base_mask</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="optimization.pruning.core.weight_masker.WeightMasker" href="weight_masker.html#optimization.pruning.core.weight_masker.WeightMasker">WeightMasker</a></b></code>:
<ul class="hlist">
<li><code><a title="optimization.pruning.core.weight_masker.WeightMasker.calc_mask" href="weight_masker.html#optimization.pruning.core.weight_masker.WeightMasker.calc_mask">calc_mask</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="optimization.pruning.core.filter_prune.ActivationMeanRankFilterPrunerMasker"><code class="flex name class">
<span>class <span class="ident">ActivationMeanRankFilterPrunerMasker</span></span>
<span>(</span><span>model, pruner, statistics_batch_num=1, activation='relu')</span>
</code></dt>
<dd>
<div class="desc"><p>A structured pruning algorithm that prunes the filters with the
smallest mean value of output activations.
Pavlo Molchanov, Stephen Tyree, Tero Karras, Timo Aila and Jan Kautz,
"Pruning Convolutional Neural Networks for Resource Efficient Inference", ICLR 2017.
<a href="https://arxiv.org/abs/1611.06440">https://arxiv.org/abs/1611.06440</a></p>
<p>A structured pruning masker base class that prunes convolutional layer filters.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>nn.Module</code></dt>
<dd>model to be pruned</dd>
<dt><strong><code>pruner</code></strong> :&ensp;<code>Pruner</code></dt>
<dd>A Pruner instance used to prune the model</dd>
<dt><strong><code>preserve_round</code></strong> :&ensp;<code>int</code></dt>
<dd>after pruning, preserve filters/channels round to <code>preserve_round</code>, for example:
for a Conv2d layer, output channel is 32, sparsity is 0.2, if preserve_round is
1 (no preserve round), then there will be int(32 * 0.2) = 6 filters pruned, and
32 - 6 = 26 filters are preserved. If preserve_round is 4, preserved filters will
be round up to 28 (which can be divided by 4) and only 4 filters are pruned.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ActivationMeanRankFilterPrunerMasker(ActivationFilterPrunerMasker):
    &#34;&#34;&#34;
    A structured pruning algorithm that prunes the filters with the
    smallest mean value of output activations.
    Pavlo Molchanov, Stephen Tyree, Tero Karras, Timo Aila and Jan Kautz,
    &#34;Pruning Convolutional Neural Networks for Resource Efficient Inference&#34;, ICLR 2017.
    https://arxiv.org/abs/1611.06440
    &#34;&#34;&#34;
    def get_mask(self, base_mask, weight, num_prune, wrapper, wrapper_idx, channel_masks=None):

        mean_activation = self.get_channel_sum(wrapper, wrapper_idx)
        if mean_activation is None:
            return None
        if channel_masks is not None:
            mean_activation = mean_activation * channel_masks

        prune_indices = torch.argsort(mean_activation)[:num_prune]
        for idx in prune_indices:
            base_mask[&#39;weight_mask&#39;][idx] = 0.
            if base_mask[&#39;bias_mask&#39;] is not None:
                base_mask[&#39;bias_mask&#39;][idx] = 0.
        if self.pruner.hook_id in self.pruner._fwd_hook_handles:
            self.pruner.remove_activation_collector(self.pruner.hook_id)

        return base_mask

    def _cal_mean_activation(self, activations):
        &#34;&#34;&#34;
        Calculate mean value of activations.

        Parameters
        ----------
        activations : list
            Layer&#39;s output activations

        Returns
        -------
        torch.Tensor
            Filter&#39;s mean value of the output activations
        &#34;&#34;&#34;
        activations = torch.cat(activations, 0)
        mean_activation = torch.mean(activations, dim=(0, 2, 3))
        return mean_activation

    def get_channel_sum(self, wrapper, wrapper_idx):
        assert wrapper_idx is not None
        activations = self.pruner.collected_activation[wrapper_idx]
        if len(activations) &lt; self.statistics_batch_num:
            return None
        return self._cal_mean_activation(activations).to(wrapper.module.weight.device)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>optimization.pruning.core.filter_prune.ActivationFilterPrunerMasker</li>
<li>optimization.pruning.core.filter_prune.StructuredWeightMasker</li>
<li><a title="optimization.pruning.core.weight_masker.WeightMasker" href="weight_masker.html#optimization.pruning.core.weight_masker.WeightMasker">WeightMasker</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="optimization.pruning.core.filter_prune.ActivationMeanRankFilterPrunerMasker.get_channel_sum"><code class="name flex">
<span>def <span class="ident">get_channel_sum</span></span>(<span>self, wrapper, wrapper_idx)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the importance weight for each channel. If want to support the
dependency-aware mode for this one-shot pruner, this function must be
implemented.
Parameters</p>
<hr>
<dl>
<dt><strong><code>wrapper</code></strong> :&ensp;<code>PrunerModuleWrapper</code></dt>
<dd>layer wrapper of this layer</dd>
<dt><strong><code>wrapper_idx</code></strong> :&ensp;<code>int</code></dt>
<dd>index of this wrapper in pruner's all wrappers</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tensor</code></dt>
<dd>Tensor that indicates the importance of each channel</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_channel_sum(self, wrapper, wrapper_idx):
    assert wrapper_idx is not None
    activations = self.pruner.collected_activation[wrapper_idx]
    if len(activations) &lt; self.statistics_batch_num:
        return None
    return self._cal_mean_activation(activations).to(wrapper.module.weight.device)</code></pre>
</details>
</dd>
<dt id="optimization.pruning.core.filter_prune.ActivationMeanRankFilterPrunerMasker.get_mask"><code class="name flex">
<span>def <span class="ident">get_mask</span></span>(<span>self, base_mask, weight, num_prune, wrapper, wrapper_idx, channel_masks=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the mask of given layer.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>base_mask</code></strong> :&ensp;<code>dict</code></dt>
<dd>The basic mask with the same shape of weight, all item in the basic mask is 1.</dd>
<dt><strong><code>weight</code></strong> :&ensp;<code>tensor</code></dt>
<dd>the module weight to be pruned</dd>
<dt><strong><code>num_prune</code></strong> :&ensp;<code>int</code></dt>
<dd>Num of filters to prune</dd>
<dt><strong><code>wrapper</code></strong> :&ensp;<code>PrunerModuleWrapper</code></dt>
<dd>layer wrapper of this layer</dd>
<dt><strong><code>wrapper_idx</code></strong> :&ensp;<code>int</code></dt>
<dd>index of this wrapper in pruner's all wrappers</dd>
<dt><strong><code>channel_masks</code></strong> :&ensp;<code>Tensor</code></dt>
<dd>If mask some channels for this layer in advance. In the dependency-aware
mode, before calculating the masks for each layer, we will calculate a common
mask for all the layers in the dependency set. For the pruners that doesnot
support dependency-aware mode, they can just ignore this parameter.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>dictionary for storing masks</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_mask(self, base_mask, weight, num_prune, wrapper, wrapper_idx, channel_masks=None):

    mean_activation = self.get_channel_sum(wrapper, wrapper_idx)
    if mean_activation is None:
        return None
    if channel_masks is not None:
        mean_activation = mean_activation * channel_masks

    prune_indices = torch.argsort(mean_activation)[:num_prune]
    for idx in prune_indices:
        base_mask[&#39;weight_mask&#39;][idx] = 0.
        if base_mask[&#39;bias_mask&#39;] is not None:
            base_mask[&#39;bias_mask&#39;][idx] = 0.
    if self.pruner.hook_id in self.pruner._fwd_hook_handles:
        self.pruner.remove_activation_collector(self.pruner.hook_id)

    return base_mask</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="optimization.pruning.core.weight_masker.WeightMasker" href="weight_masker.html#optimization.pruning.core.weight_masker.WeightMasker">WeightMasker</a></b></code>:
<ul class="hlist">
<li><code><a title="optimization.pruning.core.weight_masker.WeightMasker.calc_mask" href="weight_masker.html#optimization.pruning.core.weight_masker.WeightMasker.calc_mask">calc_mask</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="optimization.pruning.core.filter_prune.FPGMPrunerMasker"><code class="flex name class">
<span>class <span class="ident">FPGMPrunerMasker</span></span>
<span>(</span><span>model, pruner, preserve_round=1, dependency_aware=False, global_sort=False)</span>
</code></dt>
<dd>
<div class="desc"><p>A filter pruner via geometric median.
"Filter Pruning via Geometric Median for Deep Convolutional Neural Networks Acceleration",
<a href="https://arxiv.org/pdf/1811.00250.pdf">https://arxiv.org/pdf/1811.00250.pdf</a></p>
<p>A structured pruning masker base class that prunes convolutional layer filters.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>nn.Module</code></dt>
<dd>model to be pruned</dd>
<dt><strong><code>pruner</code></strong> :&ensp;<code>Pruner</code></dt>
<dd>A Pruner instance used to prune the model</dd>
<dt><strong><code>preserve_round</code></strong> :&ensp;<code>int</code></dt>
<dd>after pruning, preserve filters/channels round to <code>preserve_round</code>, for example:
for a Conv2d layer, output channel is 32, sparsity is 0.2, if preserve_round is
1 (no preserve round), then there will be int(32 * 0.2) = 6 filters pruned, and
32 - 6 = 26 filters are preserved. If preserve_round is 4, preserved filters will
be round up to 28 (which can be divided by 4) and only 4 filters are pruned.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class FPGMPrunerMasker(StructuredWeightMasker):
    &#34;&#34;&#34;
    A filter pruner via geometric median.
    &#34;Filter Pruning via Geometric Median for Deep Convolutional Neural Networks Acceleration&#34;,
    https://arxiv.org/pdf/1811.00250.pdf
    &#34;&#34;&#34;
    def get_mask(self, base_mask, weight, num_prune, wrapper, wrapper_idx, channel_masks=None):
        min_gm_idx = self._get_min_gm_kernel_idx(
            num_prune, wrapper, wrapper_idx, channel_masks)
        for idx in min_gm_idx:
            base_mask[&#39;weight_mask&#39;][idx] = 0.
            if base_mask[&#39;bias_mask&#39;] is not None:
                base_mask[&#39;bias_mask&#39;][idx] = 0.
        return base_mask

    def _get_min_gm_kernel_idx(self, num_prune, wrapper, wrapper_idx, channel_masks):
        channel_dist = self.get_channel_sum(wrapper, wrapper_idx)
        if channel_masks is not None:
            channel_dist = channel_dist * channel_masks
        dist_list = [(channel_dist[i], i) for i in range(channel_dist.size(0))]
        min_gm_kernels = sorted(dist_list, key=lambda x: x[0])[:num_prune]
        return [x[1] for x in min_gm_kernels]

    def _get_distance_sum(self, weight, out_idx):
        &#34;&#34;&#34;
        Calculate the total distance between a specified filter (by out_idex and in_idx) and
        all other filters.
        Parameters
        ----------
        weight: Tensor
            convolutional filter weight
        out_idx: int
            output channel index of specified filter, this method calculates the total distance
            between this specified filter and all other filters.
        Returns
        -------
        float32
            The total distance
        &#34;&#34;&#34;
        _logger.debug(&#39;weight size: %s&#39;, weight.size())
        assert len(weight.size()) in [3, 4], &#39;unsupported weight shape&#39;

        w = weight.view(weight.size(0), -1)
        anchor_w = w[out_idx].unsqueeze(0).expand(w.size(0), w.size(1))
        x = w - anchor_w
        x = (x * x).sum(-1)
        x = torch.sqrt(x)
        return x.sum()

    def get_channel_sum(self, wrapper, wrapper_idx):
        weight = wrapper.module.weight.data
        assert len(weight.size()) in [3, 4]
        dist_list = []
        for out_i in range(weight.size(0)):
            dist_sum = self._get_distance_sum(weight, out_i)
            dist_list.append(dist_sum)
        return torch.Tensor(dist_list).to(weight.device)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>optimization.pruning.core.filter_prune.StructuredWeightMasker</li>
<li><a title="optimization.pruning.core.weight_masker.WeightMasker" href="weight_masker.html#optimization.pruning.core.weight_masker.WeightMasker">WeightMasker</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="optimization.pruning.core.filter_prune.FPGMPrunerMasker.get_channel_sum"><code class="name flex">
<span>def <span class="ident">get_channel_sum</span></span>(<span>self, wrapper, wrapper_idx)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the importance weight for each channel. If want to support the
dependency-aware mode for this one-shot pruner, this function must be
implemented.
Parameters</p>
<hr>
<dl>
<dt><strong><code>wrapper</code></strong> :&ensp;<code>PrunerModuleWrapper</code></dt>
<dd>layer wrapper of this layer</dd>
<dt><strong><code>wrapper_idx</code></strong> :&ensp;<code>int</code></dt>
<dd>index of this wrapper in pruner's all wrappers</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tensor</code></dt>
<dd>Tensor that indicates the importance of each channel</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_channel_sum(self, wrapper, wrapper_idx):
    weight = wrapper.module.weight.data
    assert len(weight.size()) in [3, 4]
    dist_list = []
    for out_i in range(weight.size(0)):
        dist_sum = self._get_distance_sum(weight, out_i)
        dist_list.append(dist_sum)
    return torch.Tensor(dist_list).to(weight.device)</code></pre>
</details>
</dd>
<dt id="optimization.pruning.core.filter_prune.FPGMPrunerMasker.get_mask"><code class="name flex">
<span>def <span class="ident">get_mask</span></span>(<span>self, base_mask, weight, num_prune, wrapper, wrapper_idx, channel_masks=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the mask of given layer.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>base_mask</code></strong> :&ensp;<code>dict</code></dt>
<dd>The basic mask with the same shape of weight, all item in the basic mask is 1.</dd>
<dt><strong><code>weight</code></strong> :&ensp;<code>tensor</code></dt>
<dd>the module weight to be pruned</dd>
<dt><strong><code>num_prune</code></strong> :&ensp;<code>int</code></dt>
<dd>Num of filters to prune</dd>
<dt><strong><code>wrapper</code></strong> :&ensp;<code>PrunerModuleWrapper</code></dt>
<dd>layer wrapper of this layer</dd>
<dt><strong><code>wrapper_idx</code></strong> :&ensp;<code>int</code></dt>
<dd>index of this wrapper in pruner's all wrappers</dd>
<dt><strong><code>channel_masks</code></strong> :&ensp;<code>Tensor</code></dt>
<dd>If mask some channels for this layer in advance. In the dependency-aware
mode, before calculating the masks for each layer, we will calculate a common
mask for all the layers in the dependency set. For the pruners that doesnot
support dependency-aware mode, they can just ignore this parameter.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>dictionary for storing masks</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_mask(self, base_mask, weight, num_prune, wrapper, wrapper_idx, channel_masks=None):
    min_gm_idx = self._get_min_gm_kernel_idx(
        num_prune, wrapper, wrapper_idx, channel_masks)
    for idx in min_gm_idx:
        base_mask[&#39;weight_mask&#39;][idx] = 0.
        if base_mask[&#39;bias_mask&#39;] is not None:
            base_mask[&#39;bias_mask&#39;][idx] = 0.
    return base_mask</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="optimization.pruning.core.weight_masker.WeightMasker" href="weight_masker.html#optimization.pruning.core.weight_masker.WeightMasker">WeightMasker</a></b></code>:
<ul class="hlist">
<li><code><a title="optimization.pruning.core.weight_masker.WeightMasker.calc_mask" href="weight_masker.html#optimization.pruning.core.weight_masker.WeightMasker.calc_mask">calc_mask</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="optimization.pruning.core.filter_prune.L1FilterPrunerMasker"><code class="flex name class">
<span>class <span class="ident">L1FilterPrunerMasker</span></span>
<span>(</span><span>model, pruner, preserve_round=1, dependency_aware=False, global_sort=False)</span>
</code></dt>
<dd>
<div class="desc"><p>A structured pruning algorithm that prunes the filters of smallest magnitude
weights sum in the convolution layers to achieve a preset level of network sparsity.
Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet and Hans Peter Graf,
"PRUNING FILTERS FOR EFFICIENT CONVNETS", 2017 ICLR
<a href="https://arxiv.org/abs/1608.08710">https://arxiv.org/abs/1608.08710</a></p>
<p>A structured pruning masker base class that prunes convolutional layer filters.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>nn.Module</code></dt>
<dd>model to be pruned</dd>
<dt><strong><code>pruner</code></strong> :&ensp;<code>Pruner</code></dt>
<dd>A Pruner instance used to prune the model</dd>
<dt><strong><code>preserve_round</code></strong> :&ensp;<code>int</code></dt>
<dd>after pruning, preserve filters/channels round to <code>preserve_round</code>, for example:
for a Conv2d layer, output channel is 32, sparsity is 0.2, if preserve_round is
1 (no preserve round), then there will be int(32 * 0.2) = 6 filters pruned, and
32 - 6 = 26 filters are preserved. If preserve_round is 4, preserved filters will
be round up to 28 (which can be divided by 4) and only 4 filters are pruned.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class L1FilterPrunerMasker(StructuredWeightMasker):
    &#34;&#34;&#34;
    A structured pruning algorithm that prunes the filters of smallest magnitude
    weights sum in the convolution layers to achieve a preset level of network sparsity.
    Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet and Hans Peter Graf,
    &#34;PRUNING FILTERS FOR EFFICIENT CONVNETS&#34;, 2017 ICLR
    https://arxiv.org/abs/1608.08710
    &#34;&#34;&#34;

    def get_mask(self, base_mask, weight, num_prune, wrapper, wrapper_idx, channel_masks=None):
        w_abs_structured = self.get_channel_sum(wrapper, wrapper_idx)
        if channel_masks is not None:
            w_abs_structured = w_abs_structured * channel_masks
        threshold = torch.topk(w_abs_structured.view(-1),num_prune, largest=False)[0].max()
        mask_weight = torch.gt(w_abs_structured, threshold)[
            :, None, None, None].expand_as(weight).type_as(weight)
        mask_bias = torch.gt(w_abs_structured, threshold).type_as(
            weight).detach() if base_mask[&#39;bias_mask&#39;] is not None else None
        return {&#39;weight_mask&#39;: mask_weight.detach(), &#39;bias_mask&#39;: mask_bias}

    def get_channel_sum(self, wrapper, wrapper_idx):
        weight = wrapper.module.weight.data
        filters = weight.shape[0]
        w_abs = weight.abs()
        w_abs_structured = w_abs.view(filters, -1).sum(dim=1)
        return w_abs_structured</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>optimization.pruning.core.filter_prune.StructuredWeightMasker</li>
<li><a title="optimization.pruning.core.weight_masker.WeightMasker" href="weight_masker.html#optimization.pruning.core.weight_masker.WeightMasker">WeightMasker</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="optimization.pruning.core.filter_prune.L1FilterPrunerMasker.get_channel_sum"><code class="name flex">
<span>def <span class="ident">get_channel_sum</span></span>(<span>self, wrapper, wrapper_idx)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the importance weight for each channel. If want to support the
dependency-aware mode for this one-shot pruner, this function must be
implemented.
Parameters</p>
<hr>
<dl>
<dt><strong><code>wrapper</code></strong> :&ensp;<code>PrunerModuleWrapper</code></dt>
<dd>layer wrapper of this layer</dd>
<dt><strong><code>wrapper_idx</code></strong> :&ensp;<code>int</code></dt>
<dd>index of this wrapper in pruner's all wrappers</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tensor</code></dt>
<dd>Tensor that indicates the importance of each channel</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_channel_sum(self, wrapper, wrapper_idx):
    weight = wrapper.module.weight.data
    filters = weight.shape[0]
    w_abs = weight.abs()
    w_abs_structured = w_abs.view(filters, -1).sum(dim=1)
    return w_abs_structured</code></pre>
</details>
</dd>
<dt id="optimization.pruning.core.filter_prune.L1FilterPrunerMasker.get_mask"><code class="name flex">
<span>def <span class="ident">get_mask</span></span>(<span>self, base_mask, weight, num_prune, wrapper, wrapper_idx, channel_masks=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the mask of given layer.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>base_mask</code></strong> :&ensp;<code>dict</code></dt>
<dd>The basic mask with the same shape of weight, all item in the basic mask is 1.</dd>
<dt><strong><code>weight</code></strong> :&ensp;<code>tensor</code></dt>
<dd>the module weight to be pruned</dd>
<dt><strong><code>num_prune</code></strong> :&ensp;<code>int</code></dt>
<dd>Num of filters to prune</dd>
<dt><strong><code>wrapper</code></strong> :&ensp;<code>PrunerModuleWrapper</code></dt>
<dd>layer wrapper of this layer</dd>
<dt><strong><code>wrapper_idx</code></strong> :&ensp;<code>int</code></dt>
<dd>index of this wrapper in pruner's all wrappers</dd>
<dt><strong><code>channel_masks</code></strong> :&ensp;<code>Tensor</code></dt>
<dd>If mask some channels for this layer in advance. In the dependency-aware
mode, before calculating the masks for each layer, we will calculate a common
mask for all the layers in the dependency set. For the pruners that doesnot
support dependency-aware mode, they can just ignore this parameter.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>dictionary for storing masks</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_mask(self, base_mask, weight, num_prune, wrapper, wrapper_idx, channel_masks=None):
    w_abs_structured = self.get_channel_sum(wrapper, wrapper_idx)
    if channel_masks is not None:
        w_abs_structured = w_abs_structured * channel_masks
    threshold = torch.topk(w_abs_structured.view(-1),num_prune, largest=False)[0].max()
    mask_weight = torch.gt(w_abs_structured, threshold)[
        :, None, None, None].expand_as(weight).type_as(weight)
    mask_bias = torch.gt(w_abs_structured, threshold).type_as(
        weight).detach() if base_mask[&#39;bias_mask&#39;] is not None else None
    return {&#39;weight_mask&#39;: mask_weight.detach(), &#39;bias_mask&#39;: mask_bias}</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="optimization.pruning.core.weight_masker.WeightMasker" href="weight_masker.html#optimization.pruning.core.weight_masker.WeightMasker">WeightMasker</a></b></code>:
<ul class="hlist">
<li><code><a title="optimization.pruning.core.weight_masker.WeightMasker.calc_mask" href="weight_masker.html#optimization.pruning.core.weight_masker.WeightMasker.calc_mask">calc_mask</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="optimization.pruning.core.filter_prune.L2FilterPrunerMasker"><code class="flex name class">
<span>class <span class="ident">L2FilterPrunerMasker</span></span>
<span>(</span><span>model, pruner, preserve_round=1, dependency_aware=False, global_sort=False)</span>
</code></dt>
<dd>
<div class="desc"><p>A structured pruning algorithm that prunes the filters with the
smallest L2 norm of the weights.</p>
<p>A structured pruning masker base class that prunes convolutional layer filters.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>nn.Module</code></dt>
<dd>model to be pruned</dd>
<dt><strong><code>pruner</code></strong> :&ensp;<code>Pruner</code></dt>
<dd>A Pruner instance used to prune the model</dd>
<dt><strong><code>preserve_round</code></strong> :&ensp;<code>int</code></dt>
<dd>after pruning, preserve filters/channels round to <code>preserve_round</code>, for example:
for a Conv2d layer, output channel is 32, sparsity is 0.2, if preserve_round is
1 (no preserve round), then there will be int(32 * 0.2) = 6 filters pruned, and
32 - 6 = 26 filters are preserved. If preserve_round is 4, preserved filters will
be round up to 28 (which can be divided by 4) and only 4 filters are pruned.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class L2FilterPrunerMasker(StructuredWeightMasker):
    &#34;&#34;&#34;
    A structured pruning algorithm that prunes the filters with the
    smallest L2 norm of the weights.
    &#34;&#34;&#34;

    def get_mask(self, base_mask, weight, num_prune, wrapper, wrapper_idx, channel_masks=None):
        w_l2_norm = self.get_channel_sum(wrapper, wrapper_idx)
        if channel_masks is not None:
            w_l2_norm = w_l2_norm * channel_masks
        threshold = torch.topk(w_l2_norm.view(-1), num_prune, largest=False)[0].max()
        mask_weight = torch.gt(w_l2_norm, threshold)[:, None, None, None].expand_as(weight).type_as(weight)
        mask_bias = torch.gt(w_l2_norm, threshold).type_as(weight).detach() if base_mask[&#39;bias_mask&#39;] is not None else None

        return {&#39;weight_mask&#39;: mask_weight.detach(), &#39;bias_mask&#39;: mask_bias}

    def get_channel_sum(self, wrapper, wrapper_idx):
        weight = wrapper.module.weight.data
        filters = weight.shape[0]
        w = weight.view(filters, -1)
        w_l2_norm = torch.sqrt((w ** 2).sum(dim=1))
        return w_l2_norm</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>optimization.pruning.core.filter_prune.StructuredWeightMasker</li>
<li><a title="optimization.pruning.core.weight_masker.WeightMasker" href="weight_masker.html#optimization.pruning.core.weight_masker.WeightMasker">WeightMasker</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="optimization.pruning.core.filter_prune.L2FilterPrunerMasker.get_channel_sum"><code class="name flex">
<span>def <span class="ident">get_channel_sum</span></span>(<span>self, wrapper, wrapper_idx)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the importance weight for each channel. If want to support the
dependency-aware mode for this one-shot pruner, this function must be
implemented.
Parameters</p>
<hr>
<dl>
<dt><strong><code>wrapper</code></strong> :&ensp;<code>PrunerModuleWrapper</code></dt>
<dd>layer wrapper of this layer</dd>
<dt><strong><code>wrapper_idx</code></strong> :&ensp;<code>int</code></dt>
<dd>index of this wrapper in pruner's all wrappers</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tensor</code></dt>
<dd>Tensor that indicates the importance of each channel</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_channel_sum(self, wrapper, wrapper_idx):
    weight = wrapper.module.weight.data
    filters = weight.shape[0]
    w = weight.view(filters, -1)
    w_l2_norm = torch.sqrt((w ** 2).sum(dim=1))
    return w_l2_norm</code></pre>
</details>
</dd>
<dt id="optimization.pruning.core.filter_prune.L2FilterPrunerMasker.get_mask"><code class="name flex">
<span>def <span class="ident">get_mask</span></span>(<span>self, base_mask, weight, num_prune, wrapper, wrapper_idx, channel_masks=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the mask of given layer.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>base_mask</code></strong> :&ensp;<code>dict</code></dt>
<dd>The basic mask with the same shape of weight, all item in the basic mask is 1.</dd>
<dt><strong><code>weight</code></strong> :&ensp;<code>tensor</code></dt>
<dd>the module weight to be pruned</dd>
<dt><strong><code>num_prune</code></strong> :&ensp;<code>int</code></dt>
<dd>Num of filters to prune</dd>
<dt><strong><code>wrapper</code></strong> :&ensp;<code>PrunerModuleWrapper</code></dt>
<dd>layer wrapper of this layer</dd>
<dt><strong><code>wrapper_idx</code></strong> :&ensp;<code>int</code></dt>
<dd>index of this wrapper in pruner's all wrappers</dd>
<dt><strong><code>channel_masks</code></strong> :&ensp;<code>Tensor</code></dt>
<dd>If mask some channels for this layer in advance. In the dependency-aware
mode, before calculating the masks for each layer, we will calculate a common
mask for all the layers in the dependency set. For the pruners that doesnot
support dependency-aware mode, they can just ignore this parameter.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>dictionary for storing masks</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_mask(self, base_mask, weight, num_prune, wrapper, wrapper_idx, channel_masks=None):
    w_l2_norm = self.get_channel_sum(wrapper, wrapper_idx)
    if channel_masks is not None:
        w_l2_norm = w_l2_norm * channel_masks
    threshold = torch.topk(w_l2_norm.view(-1), num_prune, largest=False)[0].max()
    mask_weight = torch.gt(w_l2_norm, threshold)[:, None, None, None].expand_as(weight).type_as(weight)
    mask_bias = torch.gt(w_l2_norm, threshold).type_as(weight).detach() if base_mask[&#39;bias_mask&#39;] is not None else None

    return {&#39;weight_mask&#39;: mask_weight.detach(), &#39;bias_mask&#39;: mask_bias}</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="optimization.pruning.core.weight_masker.WeightMasker" href="weight_masker.html#optimization.pruning.core.weight_masker.WeightMasker">WeightMasker</a></b></code>:
<ul class="hlist">
<li><code><a title="optimization.pruning.core.weight_masker.WeightMasker.calc_mask" href="weight_masker.html#optimization.pruning.core.weight_masker.WeightMasker.calc_mask">calc_mask</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="optimization.pruning.core.filter_prune.SlimPrunerMasker"><code class="flex name class">
<span>class <span class="ident">SlimPrunerMasker</span></span>
<span>(</span><span>model, pruner, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>A structured pruning algorithm that prunes channels by pruning the weights of BN layers.
Zhuang Liu, Jianguo Li, Zhiqiang Shen, Gao Huang, Shoumeng Yan and Changshui Zhang
"Learning Efficient Convolutional Networks through Network Slimming", 2017 ICCV
<a href="https://arxiv.org/pdf/1708.06519.pdf">https://arxiv.org/pdf/1708.06519.pdf</a></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SlimPrunerMasker(WeightMasker):
    &#34;&#34;&#34;
    A structured pruning algorithm that prunes channels by pruning the weights of BN layers.
    Zhuang Liu, Jianguo Li, Zhiqiang Shen, Gao Huang, Shoumeng Yan and Changshui Zhang
    &#34;Learning Efficient Convolutional Networks through Network Slimming&#34;, 2017 ICCV
    https://arxiv.org/pdf/1708.06519.pdf
    &#34;&#34;&#34;
    def __init__(self, model, pruner, **kwargs):
        super().__init__(model, pruner)
        self.global_threshold = None

    def _get_global_threshold(self):
        weight_list = []
        for (layer, _) in self.pruner.get_modules_to_compress():
            weight_list.append(layer.module.weight.data.abs().clone())
        all_bn_weights = torch.cat(weight_list)
        k = int(all_bn_weights.shape[0] * self.pruner.config_list[0][&#39;sparsity&#39;])
        self.global_threshold = torch.topk(all_bn_weights.view(-1), k, largest=False)[0].max()
        print(f&#39;set global threshold to {self.global_threshold}&#39;)

    def calc_mask(self, sparsity, wrapper, wrapper_idx=None):
        assert wrapper.type == &#39;BatchNorm2d&#39;, &#39;SlimPruner only supports 2d batch normalization layer pruning&#39;

        if self.global_threshold is None:
            self._get_global_threshold()

        weight = wrapper.module.weight.data.clone()
        if wrapper.weight_mask is not None:
            weight = weight * wrapper.weight_mask

        base_mask = torch.ones(weight.size()).type_as(weight).detach()
        mask = {&#39;weight_mask&#39;: base_mask.detach(), &#39;bias_mask&#39;: base_mask.clone().detach()}
        filters = weight.size(0)
        num_prune = int(filters * sparsity)
        if filters &gt;= 2 and num_prune &gt;= 1:
            w_abs = weight.abs()
            mask_weight = torch.gt(
                w_abs, self.global_threshold).type_as(weight)
            mask_bias = mask_weight.clone()
            mask = {&#39;weight_mask&#39;: mask_weight.detach(), &#39;bias_mask&#39;: mask_bias.detach()}
        return mask</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="optimization.pruning.core.weight_masker.WeightMasker" href="weight_masker.html#optimization.pruning.core.weight_masker.WeightMasker">WeightMasker</a></li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="optimization.pruning.core.weight_masker.WeightMasker" href="weight_masker.html#optimization.pruning.core.weight_masker.WeightMasker">WeightMasker</a></b></code>:
<ul class="hlist">
<li><code><a title="optimization.pruning.core.weight_masker.WeightMasker.calc_mask" href="weight_masker.html#optimization.pruning.core.weight_masker.WeightMasker.calc_mask">calc_mask</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="optimization.pruning.core.filter_prune.TaylorFOWeightFilterPrunerMasker"><code class="flex name class">
<span>class <span class="ident">TaylorFOWeightFilterPrunerMasker</span></span>
<span>(</span><span>model, pruner, statistics_batch_num=1)</span>
</code></dt>
<dd>
<div class="desc"><p>A structured pruning algorithm that prunes the filters with the smallest
importance approximations based on the first order taylor expansion on the weight.
Molchanov, Pavlo and Mallya, Arun and Tyree, Stephen and Frosio, Iuri and Kautz, Jan,
"Importance Estimation for Neural Network Pruning", CVPR 2019.
<a href="http://jankautz.com/publications/Importance4NNPruning_CVPR19.pdf">http://jankautz.com/publications/Importance4NNPruning_CVPR19.pdf</a></p>
<p>A structured pruning masker base class that prunes convolutional layer filters.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>nn.Module</code></dt>
<dd>model to be pruned</dd>
<dt><strong><code>pruner</code></strong> :&ensp;<code>Pruner</code></dt>
<dd>A Pruner instance used to prune the model</dd>
<dt><strong><code>preserve_round</code></strong> :&ensp;<code>int</code></dt>
<dd>after pruning, preserve filters/channels round to <code>preserve_round</code>, for example:
for a Conv2d layer, output channel is 32, sparsity is 0.2, if preserve_round is
1 (no preserve round), then there will be int(32 * 0.2) = 6 filters pruned, and
32 - 6 = 26 filters are preserved. If preserve_round is 4, preserved filters will
be round up to 28 (which can be divided by 4) and only 4 filters are pruned.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TaylorFOWeightFilterPrunerMasker(StructuredWeightMasker):    
    &#34;&#34;&#34;
    A structured pruning algorithm that prunes the filters with the smallest
    importance approximations based on the first order taylor expansion on the weight.
    Molchanov, Pavlo and Mallya, Arun and Tyree, Stephen and Frosio, Iuri and Kautz, Jan,
    &#34;Importance Estimation for Neural Network Pruning&#34;, CVPR 2019.
    http://jankautz.com/publications/Importance4NNPruning_CVPR19.pdf
    &#34;&#34;&#34;
    def __init__(self, model, pruner, statistics_batch_num=1):
        super().__init__(model, pruner)
        self.statistics_batch_num = statistics_batch_num
        self.pruner.iterations = 0
        self.pruner.set_wrappers_attribute(&#34;contribution&#34;, None)
        self.pruner.patch_optimizer(self.calc_contributions)
        self.global_threshold = None

    def _get_global_threshold(self):
        channel_contribution_list = []
        for wrapper_idx, wrapper in enumerate(self.pruner.get_modules_wrapper()):
            channel_contribution = self.get_channel_sum(wrapper, wrapper_idx)
            wrapper_size = wrapper.module.weight.size().numel()
            channel_size = wrapper.module.weight.size(0)
            contribution_expand = channel_contribution.expand(int(wrapper_size / channel_size), channel_size).reshape(-1)
            channel_contribution_list.append(contribution_expand)
        all_channel_contributions = torch.cat(channel_contribution_list)
        k = int(all_channel_contributions.shape[0] * self.pruner.config_list[0][&#39;sparsity&#39;])
        self.global_threshold = torch.topk(
            all_channel_contributions.view(-1), k, largest=False)[0].max()
    
    def _get_global_num_prune(self, wrapper, wrapper_idx):
        if self.global_threshold is None:
            self._get_global_threshold()
        weight = wrapper.module.weight.data
        filters = weight.size(0)
        channel_contribution = self.get_channel_sum(wrapper, wrapper_idx)
        num_prune = channel_contribution[channel_contribution &lt; self.global_threshold].size()[0]
        if num_prune == filters:
            num_prune -= 1
        return num_prune

    def get_mask(self, base_mask, weight, num_prune, wrapper, wrapper_idx, channel_masks=None):
        channel_contribution = self.get_channel_sum(wrapper, wrapper_idx)
        if channel_contribution is None:
            return None
        if channel_masks is not None:
            channel_contribution = channel_contribution * channel_masks
        prune_indices = torch.argsort(channel_contribution)[:num_prune]
        for idx in prune_indices:
            base_mask[&#39;weight_mask&#39;][idx] = 0.
            if base_mask[&#39;bias_mask&#39;] is not None:
                base_mask[&#39;bias_mask&#39;][idx] = 0.
        return base_mask

    def calc_contributions(self):
        &#34;&#34;&#34;
        Calculate the estimated importance of filters as a sum of individual contribution
        based on the first order taylor expansion.
        &#34;&#34;&#34;
        if self.pruner.iterations &gt;= self.statistics_batch_num:
            return

        for wrapper in self.pruner.get_modules_wrapper():
            filters = wrapper.module.weight.size(0)
            contribution = (
                wrapper.module.weight * wrapper.module.weight.grad).data.pow(2).view(filters, -1).sum(dim=1)
            if wrapper.contribution is None:
                wrapper.contribution = contribution
            else:
                wrapper.contribution += contribution

        self.pruner.iterations += 1

    def get_channel_sum(self, wrapper, wrapper_idx):
        if self.pruner.iterations &lt; self.statistics_batch_num:
            return None
        if wrapper.contribution is None:
            return None
        return wrapper.contribution</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>optimization.pruning.core.filter_prune.StructuredWeightMasker</li>
<li><a title="optimization.pruning.core.weight_masker.WeightMasker" href="weight_masker.html#optimization.pruning.core.weight_masker.WeightMasker">WeightMasker</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="optimization.pruning.core.filter_prune.TaylorFOWeightFilterPrunerMasker.calc_contributions"><code class="name flex">
<span>def <span class="ident">calc_contributions</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the estimated importance of filters as a sum of individual contribution
based on the first order taylor expansion.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_contributions(self):
    &#34;&#34;&#34;
    Calculate the estimated importance of filters as a sum of individual contribution
    based on the first order taylor expansion.
    &#34;&#34;&#34;
    if self.pruner.iterations &gt;= self.statistics_batch_num:
        return

    for wrapper in self.pruner.get_modules_wrapper():
        filters = wrapper.module.weight.size(0)
        contribution = (
            wrapper.module.weight * wrapper.module.weight.grad).data.pow(2).view(filters, -1).sum(dim=1)
        if wrapper.contribution is None:
            wrapper.contribution = contribution
        else:
            wrapper.contribution += contribution

    self.pruner.iterations += 1</code></pre>
</details>
</dd>
<dt id="optimization.pruning.core.filter_prune.TaylorFOWeightFilterPrunerMasker.get_channel_sum"><code class="name flex">
<span>def <span class="ident">get_channel_sum</span></span>(<span>self, wrapper, wrapper_idx)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the importance weight for each channel. If want to support the
dependency-aware mode for this one-shot pruner, this function must be
implemented.
Parameters</p>
<hr>
<dl>
<dt><strong><code>wrapper</code></strong> :&ensp;<code>PrunerModuleWrapper</code></dt>
<dd>layer wrapper of this layer</dd>
<dt><strong><code>wrapper_idx</code></strong> :&ensp;<code>int</code></dt>
<dd>index of this wrapper in pruner's all wrappers</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tensor</code></dt>
<dd>Tensor that indicates the importance of each channel</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_channel_sum(self, wrapper, wrapper_idx):
    if self.pruner.iterations &lt; self.statistics_batch_num:
        return None
    if wrapper.contribution is None:
        return None
    return wrapper.contribution</code></pre>
</details>
</dd>
<dt id="optimization.pruning.core.filter_prune.TaylorFOWeightFilterPrunerMasker.get_mask"><code class="name flex">
<span>def <span class="ident">get_mask</span></span>(<span>self, base_mask, weight, num_prune, wrapper, wrapper_idx, channel_masks=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the mask of given layer.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>base_mask</code></strong> :&ensp;<code>dict</code></dt>
<dd>The basic mask with the same shape of weight, all item in the basic mask is 1.</dd>
<dt><strong><code>weight</code></strong> :&ensp;<code>tensor</code></dt>
<dd>the module weight to be pruned</dd>
<dt><strong><code>num_prune</code></strong> :&ensp;<code>int</code></dt>
<dd>Num of filters to prune</dd>
<dt><strong><code>wrapper</code></strong> :&ensp;<code>PrunerModuleWrapper</code></dt>
<dd>layer wrapper of this layer</dd>
<dt><strong><code>wrapper_idx</code></strong> :&ensp;<code>int</code></dt>
<dd>index of this wrapper in pruner's all wrappers</dd>
<dt><strong><code>channel_masks</code></strong> :&ensp;<code>Tensor</code></dt>
<dd>If mask some channels for this layer in advance. In the dependency-aware
mode, before calculating the masks for each layer, we will calculate a common
mask for all the layers in the dependency set. For the pruners that doesnot
support dependency-aware mode, they can just ignore this parameter.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>dictionary for storing masks</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_mask(self, base_mask, weight, num_prune, wrapper, wrapper_idx, channel_masks=None):
    channel_contribution = self.get_channel_sum(wrapper, wrapper_idx)
    if channel_contribution is None:
        return None
    if channel_masks is not None:
        channel_contribution = channel_contribution * channel_masks
    prune_indices = torch.argsort(channel_contribution)[:num_prune]
    for idx in prune_indices:
        base_mask[&#39;weight_mask&#39;][idx] = 0.
        if base_mask[&#39;bias_mask&#39;] is not None:
            base_mask[&#39;bias_mask&#39;][idx] = 0.
    return base_mask</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="optimization.pruning.core.weight_masker.WeightMasker" href="weight_masker.html#optimization.pruning.core.weight_masker.WeightMasker">WeightMasker</a></b></code>:
<ul class="hlist">
<li><code><a title="optimization.pruning.core.weight_masker.WeightMasker.calc_mask" href="weight_masker.html#optimization.pruning.core.weight_masker.WeightMasker.calc_mask">calc_mask</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="optimization.pruning.core" href="index.html">optimization.pruning.core</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="optimization.pruning.core.filter_prune.ActivationAPoZRankFilterPrunerMasker" href="#optimization.pruning.core.filter_prune.ActivationAPoZRankFilterPrunerMasker">ActivationAPoZRankFilterPrunerMasker</a></code></h4>
<ul class="">
<li><code><a title="optimization.pruning.core.filter_prune.ActivationAPoZRankFilterPrunerMasker.get_channel_sum" href="#optimization.pruning.core.filter_prune.ActivationAPoZRankFilterPrunerMasker.get_channel_sum">get_channel_sum</a></code></li>
<li><code><a title="optimization.pruning.core.filter_prune.ActivationAPoZRankFilterPrunerMasker.get_mask" href="#optimization.pruning.core.filter_prune.ActivationAPoZRankFilterPrunerMasker.get_mask">get_mask</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="optimization.pruning.core.filter_prune.ActivationMeanRankFilterPrunerMasker" href="#optimization.pruning.core.filter_prune.ActivationMeanRankFilterPrunerMasker">ActivationMeanRankFilterPrunerMasker</a></code></h4>
<ul class="">
<li><code><a title="optimization.pruning.core.filter_prune.ActivationMeanRankFilterPrunerMasker.get_channel_sum" href="#optimization.pruning.core.filter_prune.ActivationMeanRankFilterPrunerMasker.get_channel_sum">get_channel_sum</a></code></li>
<li><code><a title="optimization.pruning.core.filter_prune.ActivationMeanRankFilterPrunerMasker.get_mask" href="#optimization.pruning.core.filter_prune.ActivationMeanRankFilterPrunerMasker.get_mask">get_mask</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="optimization.pruning.core.filter_prune.FPGMPrunerMasker" href="#optimization.pruning.core.filter_prune.FPGMPrunerMasker">FPGMPrunerMasker</a></code></h4>
<ul class="">
<li><code><a title="optimization.pruning.core.filter_prune.FPGMPrunerMasker.get_channel_sum" href="#optimization.pruning.core.filter_prune.FPGMPrunerMasker.get_channel_sum">get_channel_sum</a></code></li>
<li><code><a title="optimization.pruning.core.filter_prune.FPGMPrunerMasker.get_mask" href="#optimization.pruning.core.filter_prune.FPGMPrunerMasker.get_mask">get_mask</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="optimization.pruning.core.filter_prune.L1FilterPrunerMasker" href="#optimization.pruning.core.filter_prune.L1FilterPrunerMasker">L1FilterPrunerMasker</a></code></h4>
<ul class="">
<li><code><a title="optimization.pruning.core.filter_prune.L1FilterPrunerMasker.get_channel_sum" href="#optimization.pruning.core.filter_prune.L1FilterPrunerMasker.get_channel_sum">get_channel_sum</a></code></li>
<li><code><a title="optimization.pruning.core.filter_prune.L1FilterPrunerMasker.get_mask" href="#optimization.pruning.core.filter_prune.L1FilterPrunerMasker.get_mask">get_mask</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="optimization.pruning.core.filter_prune.L2FilterPrunerMasker" href="#optimization.pruning.core.filter_prune.L2FilterPrunerMasker">L2FilterPrunerMasker</a></code></h4>
<ul class="">
<li><code><a title="optimization.pruning.core.filter_prune.L2FilterPrunerMasker.get_channel_sum" href="#optimization.pruning.core.filter_prune.L2FilterPrunerMasker.get_channel_sum">get_channel_sum</a></code></li>
<li><code><a title="optimization.pruning.core.filter_prune.L2FilterPrunerMasker.get_mask" href="#optimization.pruning.core.filter_prune.L2FilterPrunerMasker.get_mask">get_mask</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="optimization.pruning.core.filter_prune.SlimPrunerMasker" href="#optimization.pruning.core.filter_prune.SlimPrunerMasker">SlimPrunerMasker</a></code></h4>
</li>
<li>
<h4><code><a title="optimization.pruning.core.filter_prune.TaylorFOWeightFilterPrunerMasker" href="#optimization.pruning.core.filter_prune.TaylorFOWeightFilterPrunerMasker">TaylorFOWeightFilterPrunerMasker</a></code></h4>
<ul class="">
<li><code><a title="optimization.pruning.core.filter_prune.TaylorFOWeightFilterPrunerMasker.calc_contributions" href="#optimization.pruning.core.filter_prune.TaylorFOWeightFilterPrunerMasker.calc_contributions">calc_contributions</a></code></li>
<li><code><a title="optimization.pruning.core.filter_prune.TaylorFOWeightFilterPrunerMasker.get_channel_sum" href="#optimization.pruning.core.filter_prune.TaylorFOWeightFilterPrunerMasker.get_channel_sum">get_channel_sum</a></code></li>
<li><code><a title="optimization.pruning.core.filter_prune.TaylorFOWeightFilterPrunerMasker.get_mask" href="#optimization.pruning.core.filter_prune.TaylorFOWeightFilterPrunerMasker.get_mask">get_mask</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>